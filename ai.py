from pathlib import Path
from openai import OpenAI
import base64
import os
import json

OPEN_AI_KEY="sk-proj-q6BSzVRt5SiFl9u1O57oT3BlbkFJ3sjkvfOiMnj32W4fxQgN"  # Replace "YOUR_OPENAI_KEY" with your OpenAI key

def create_audio(text):
  """
  Creates an audio file from the provided text using OpenAI's text-to-speech service.

  Args:
      text (str): The text to be converted into speech.

  Returns:
      str: The base64 encoded string of the generated audio file.
  """

  client = OpenAI(api_key=OPEN_AI_KEY)  

  response = client.audio.speech.create(    # https://platform.openai.com/docs/guides/text-to-speech
    model="tts-1",
    voice="alloy",
    input=text
  )

  binary = response.read()
  base64_encoded_data = base64.b64encode(binary)   # convert binary into base64 for Recall

  return base64_encoded_data.decode('utf-8')


def read_memory():
  """
  Reads the current calls ChatGPT memory from a JSON file and returns the data.

  Returns:
      dict: The data read from the memory JSON file.
  """
  with open('memory.json', 'r') as file:
    data = json.load(file)
  return data


def memorize(new_memory):
    """
    Writes new speech from user and response from GPT to memory.

    Args:
        new_memory (dict: {role: str, content: str}): The memory data to be written to the file.
    """
    with open("memory.json", "w") as file:
        json.dump(new_memory, file, indent=4)

def initialize_memory():
    """
    Initializes the memory with default system and assistant roles and writes it to a JSON file.
    """
    initial_memory = [
        {
            "role": "system",
            "content": (
                "You are talking to a friend, be helpful and thoughtful and ask them questions about themselves."
            )
        },
        {
            "role": "assistant",
            "content": (
                "Hey! Thanks for letting me into the zoom call. My name is Recally, I'm here to chat about, well, anything! What's on your mind?"
            )
        }
    ]

    with open("memory.json", "w") as file:
        json.dump(initial_memory, file, indent=4)


def generate_response(text):
    """
    Generates a response based on the input text using OpenAI's chat completion service,
    updates the memory, and saves the new memory state.

    Args:
        text (str): The input text from the user.

    Returns:
        str: The response text generated by the assistant.
    """
    client = OpenAI(api_key=OPEN_AI_KEY)

    memory = read_memory()
    memory.append({"role": "user", "content": text})
    
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=memory
    )

    response_text = response.choices[0].message.content
    memory.append({"role": "assistant", "content": response_text})

    memorize(memory)

    return response_text